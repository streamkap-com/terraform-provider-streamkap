// Code generated by tfgen. DO NOT EDIT.

package generated

import (
	"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringdefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
)

// DestinationR2Model is the Terraform model for the r2 destination.
type DestinationR2Model struct {
	ID                  types.String `tfsdk:"id"`
	Name                types.String `tfsdk:"name"`
	Connector           types.String `tfsdk:"connector"`
	R2Account           types.String `tfsdk:"r2_account"`
	AWSAccessKeyID      types.String `tfsdk:"aws_access_key_id"`
	AWSSecretAccessKey  types.String `tfsdk:"aws_secret_access_key"`
	AWSS3BucketName     types.String `tfsdk:"aws_s3_bucket_name"`
	Format              types.String `tfsdk:"format"`
	FileNameTemplate    types.String `tfsdk:"file_name_template"`
	FileNamePrefix      types.String `tfsdk:"file_name_prefix"`
	FileCompressionType types.String `tfsdk:"file_compression_type"`
	FormatOutputFields  types.List   `tfsdk:"format_output_fields"`
}

// DestinationR2Schema returns the Terraform schema for the r2 destination.
func DestinationR2Schema() schema.Schema {
	return schema.Schema{
		Description: "Manages a R2 destination connector.",
		MarkdownDescription: "Manages a **R2 destination connector**.\n\n" +
			"This resource creates and manages a R2 destination for Streamkap data pipelines.\n\n" +
			"[Documentation](https://docs.streamkap.com/streamkap-provider-for-terraform)",
		Attributes: map[string]schema.Attribute{
			"id": schema.StringAttribute{
				Computed:            true,
				Description:         "Unique identifier for the destination",
				MarkdownDescription: "Unique identifier for the destination",
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
			"name": schema.StringAttribute{
				Required:            true,
				Description:         "Name of the destination",
				MarkdownDescription: "Name of the destination",
			},
			"connector": schema.StringAttribute{
				Computed:            true,
				Description:         "Connector type",
				MarkdownDescription: "Connector type",
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
			"r2_account": schema.StringAttribute{
				Required:            true,
				Description:         "your Cloudflare R2 account ID. This is the account ID you see in the Cloudflare dashboard.",
				MarkdownDescription: "your Cloudflare R2 account ID. This is the account ID you see in the Cloudflare dashboard.",
			},
			"aws_access_key_id": schema.StringAttribute{
				Required:            true,
				Description:         "The Access Key ID used to connect to R2.",
				MarkdownDescription: "The Access Key ID used to connect to R2.",
			},
			"aws_secret_access_key": schema.StringAttribute{
				Required:            true,
				Sensitive:           true,
				Description:         "The Secret Access Key used to connect to R2. This value is sensitive and will not appear in logs or CLI output.",
				MarkdownDescription: "The Secret Access Key used to connect to R2.\n\n**Security:** This value is marked sensitive and will not appear in CLI output or logs.",
			},
			"aws_s3_bucket_name": schema.StringAttribute{
				Required:            true,
				Description:         "The R2 Bucket to use.",
				MarkdownDescription: "The R2 Bucket to use.",
			},
			"format": schema.StringAttribute{
				Optional:            true,
				Computed:            true,
				Description:         "The format to use when writing data to the store. Defaults to \"JSON Array\". Valid values: JSON Lines, JSON Array, Parquet.",
				MarkdownDescription: "The format to use when writing data to the store. Defaults to `JSON Array`. Valid values: `JSON Lines`, `JSON Array`, `Parquet`.",
				Default:             stringdefault.StaticString("JSON Array"),
				Validators: []validator.String{
					stringvalidator.OneOf("JSON Lines", "JSON Array", "Parquet"),
				},
			},
			"file_name_template": schema.StringAttribute{
				Optional:            true,
				Computed:            true,
				Description:         "The format of the filename. See documentation for more information about formatting options. Defaults to \"{{topic}}-{{partition}}-{{start_offset}}\".",
				MarkdownDescription: "The format of the filename. See documentation for more information about formatting options. Defaults to `{{topic}}-{{partition}}-{{start_offset}}`.",
				Default:             stringdefault.StaticString("{{topic}}-{{partition}}-{{start_offset}}"),
			},
			"file_name_prefix": schema.StringAttribute{
				Optional:            true,
				Description:         "Prefix for the filename. Prefixes can be used to specify a directory for the file (e.g. dir1/dir2/).",
				MarkdownDescription: "Prefix for the filename. Prefixes can be used to specify a directory for the file (e.g. dir1/dir2/).",
			},
			"file_compression_type": schema.StringAttribute{
				Optional:            true,
				Computed:            true,
				Description:         "Compression type for files written to S3. Defaults to \"gzip\". Valid values: none, gzip, snappy, zstd.",
				MarkdownDescription: "Compression type for files written to S3. Defaults to `gzip`. Valid values: `none`, `gzip`, `snappy`, `zstd`.",
				Default:             stringdefault.StaticString("gzip"),
				Validators: []validator.String{
					stringvalidator.OneOf("none", "gzip", "snappy", "zstd"),
				},
			},
			"format_output_fields": schema.ListAttribute{
				Optional:            true,
				Computed:            true,
				ElementType:         types.StringType,
				Description:         "A comma separated list of fields to include in output? Options to include key, offset, timestamp, value, headers.",
				MarkdownDescription: "A comma separated list of fields to include in output? Options to include key, offset, timestamp, value, headers.",
			},
		},
	}
}

// DestinationR2FieldMappings maps Terraform attribute names to API field names.
var DestinationR2FieldMappings = map[string]string{
	"r2_account":            "r2.account.user.defined",
	"aws_access_key_id":     "aws.access.key.id",
	"aws_secret_access_key": "aws.secret.access.key",
	"aws_s3_bucket_name":    "aws.s3.bucket.name",
	"format":                "format.user.defined",
	"file_name_template":    "file.name.template",
	"file_name_prefix":      "file.name.prefix",
	"file_compression_type": "file.compression.type",
	"format_output_fields":  "format.output.fields.user.defined",
}
