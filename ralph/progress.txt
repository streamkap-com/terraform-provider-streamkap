# Ralph Progress Log
# Feature: conditional-validation-struct-alignment
# Started: 2026-01-22

## Codebase Patterns
- Backend config files use `config` array (not `configuration`) in `configuration.latest.json`
- Conditional fields have `conditions` array with objects containing `operator`, `config`, `value`
- Field names in backend use dots (e.g., `signal.data.collection.schema.or.database`)
- Field names in Terraform use underscores (e.g., `signal_data_collection_schema_or_database`)
- Files with conditions and `required: true` in backend should be `Optional: true` in Terraform
- User-defined fields (`user_defined: true`) are the ones that appear in Terraform schemas

## 2026-01-22 09:12 - US-001
- What was implemented:
  - Parsed all configuration.latest.json files across sources, destinations, transforms plugins
  - Identified 159 conditional fields across 32 connectors
  - Found 13 fields across 9 source connectors marked Required in Terraform but with conditions in backend
  - Created comprehensive audit report at docs/audits/conditional-fields-audit.md
- Files changed:
  - docs/audits/conditional-fields-audit.md (created/updated)
- **Learnings for future iterations:**
  - Backend config structure: Look for `config` key (not `configuration`) for the field definitions
  - Fields with `user_defined: true` are the ones exposed in Terraform
  - The condition `operator` is typically "EQ" and `config` is the field name, `value` is the expected value
  - SSH-related fields (`ssh_host`, `ssh_port`, `ssh_user`, `ssh_public_key_user_displayed`) are commonly conditional on `ssh.enabled=true`
  - Signal/heartbeat table schema fields are commonly conditional on snapshot/heartbeat settings
---

## 2026-01-22 10:15 - US-002
- What was implemented:
  - Added `Timeouts timeouts.Value` field to `PipelineResourceModel` struct with `tfsdk:"timeouts"` tag
  - Verified CRUD methods already handle timeouts correctly (Create, Update, Delete all properly get timeouts from config/state)
- Files changed:
  - internal/resource/pipeline/pipeline.go (added 1 line to struct)
- **Learnings for future iterations:**
  - When a schema defines a `timeouts` block, the corresponding struct MUST have a `Timeouts timeouts.Value` field with `tfsdk:"timeouts"` tag
  - The timeouts block is defined in schema using `timeouts.Block(ctx, timeouts.Opts{Create: true, Update: true, Delete: true})`
  - CRUD methods get timeouts via `req.Config.GetAttribute(ctx, path.Root("timeouts"), &timeoutsValue)` (Create/Update) or `req.State.GetAttribute()` (Delete)
  - This is a common pattern - if schema has a block, struct needs a corresponding field
---

## 2026-01-22 11:30 - US-003
- What was implemented:
  - Added 4 deprecated field schema attributes to SourcePostgresqlSchema() in internal/generated/source_postgresql.go
  - insert_static_key_field_1 → transforms_insert_static_key1_static_field
  - insert_static_key_value_1 → transforms_insert_static_key1_static_value
  - insert_static_value_field_1 → transforms_insert_static_value1_static_field
  - insert_static_value_1 → transforms_insert_static_value1_static_value
  - All fields: Optional: true, Computed: true, Default: stringdefault.StaticString(""), with DeprecationMessage
- Files changed:
  - internal/generated/source_postgresql.go (added schema attributes for deprecated fields)
- **Learnings for future iterations:**
  - When struct has fields with `tfsdk` tags, schema MUST have corresponding attributes or Terraform will fail to unmarshal
  - Deprecated fields need: Optional: true, Computed: true, DeprecationMessage, and a Default value
  - Default: stringdefault.StaticString("") is appropriate for deprecated string fields that should be empty by default
  - DeprecationMessage in Terraform shows a warning when users use the deprecated field
---

## 2026-01-22 12:45 - US-004
- What was implemented:
  - Added 5 remaining deprecated field schema attributes to SourcePostgresqlSchema() in internal/generated/source_postgresql.go
  - insert_static_key_field_2 → transforms_insert_static_key2_static_field
  - insert_static_key_value_2 → transforms_insert_static_key2_static_value
  - insert_static_value_field_2 → transforms_insert_static_value2_static_field
  - insert_static_value_2 → transforms_insert_static_value2_static_value
  - predicates_istopictoenrich_pattern → predicates_is_topic_to_enrich_pattern
  - All fields: Optional: true, Computed: true, Default: stringdefault.StaticString(""), with DeprecationMessage
- Files changed:
  - internal/generated/source_postgresql.go (added schema attributes for remaining deprecated fields)
- **Learnings for future iterations:**
  - The pattern for deprecated fields is consistent: Optional: true, Computed: true, DeprecationMessage, Default: stringdefault.StaticString("")
  - When struct has tfsdk-tagged fields, ALL of them must have corresponding schema attributes
  - Check struct definition to identify all deprecated fields that need schema attributes
---

## 2026-01-22 14:30 - US-005
- What was implemented:
  - Added 9 deprecated field mappings to SourcePostgresqlFieldMappings in internal/generated/source_postgresql.go
  - insert_static_key_field_1 → transforms.InsertStaticKey1.static.field
  - insert_static_key_value_1 → transforms.InsertStaticKey1.static.value
  - insert_static_value_field_1 → transforms.InsertStaticValue1.static.field
  - insert_static_value_1 → transforms.InsertStaticValue1.static.value
  - insert_static_key_field_2 → transforms.InsertStaticKey2.static.field
  - insert_static_key_value_2 → transforms.InsertStaticKey2.static.value
  - insert_static_value_field_2 → transforms.InsertStaticValue2.static.field
  - insert_static_value_2 → transforms.InsertStaticValue2.static.value
  - predicates_istopictoenrich_pattern → predicates.IsTopicToEnrich.pattern
- Files changed:
  - internal/generated/source_postgresql.go (added field mappings for deprecated fields)
- **Learnings for future iterations:**
  - FieldMappings map connects Terraform attribute names to API field names (with dots)
  - Deprecated fields need mappings that point to the SAME API key as their replacement fields
  - This allows deprecated fields to continue working while users migrate to the new field names
  - The mapping pattern is: `"terraform_field_name": "api.field.name.with.dots"`
---

## 2026-01-22 16:00 - US-006
- What was implemented:
  - Changed signal_data_collection_schema_or_database from Required to Optional with Computed
  - Added Default: stringdefault.StaticString("public") for signal_data_collection_schema_or_database
  - Changed heartbeat_data_collection_schema_or_database from Required to Optional
  - Updated descriptions for both fields to document when they are conditionally required
  - signal_data_collection_schema_or_database: conditionally required when snapshot_read_only is "No"
  - heartbeat_data_collection_schema_or_database: conditionally required when heartbeat_enabled is true AND snapshot_read_only is "No"
- Files changed:
  - internal/generated/source_postgresql.go (modified schema attributes for conditional fields)
- **Learnings for future iterations:**
  - Fields with conditions in backend config should be Optional in Terraform, not Required
  - When a field has a logical default value (like "public" for schema), add a Default
  - Fields that are conditionally required but have no obvious default should be Optional without Computed
  - Document conditions in the Description and MarkdownDescription for user clarity
  - The condition logic typically uses AND between multiple conditions in the backend
---

## 2026-01-22 17:15 - US-007
- What was implemented:
  - Changed heartbeat_data_collection_schema_or_database from Required to Optional in MySQL schema
  - Updated descriptions to document the conditional requirement (heartbeat_enabled=true AND snapshot_gtid="No")
  - Most MySQL conditional fields were already correctly marked Optional
- Files changed:
  - internal/generated/source_mysql.go (modified schema attribute for heartbeat_data_collection_schema_or_database)
- **Learnings for future iterations:**
  - MySQL follows similar patterns to PostgreSQL for conditional fields
  - The heartbeat_data_collection_schema_or_database field has same condition pattern: heartbeat_enabled AND read-only mode disabled
  - MySQL uses snapshot_gtid="No" where PostgreSQL uses snapshot_read_only="No"
  - Always review the full conditions array in backend - multiple conditions are ANDed together
---

## 2026-01-22 18:30 - US-008
- What was implemented:
  - Updated descriptions for all MongoDB SSH-related conditional fields to document when they are required
  - ssh_host: Required when ssh_enabled is true
  - ssh_port: Required when ssh_enabled is true
  - ssh_user: Required when ssh_enabled is true
  - ssh_public_key: Required when ssh_enabled is true
  - All SSH fields were already correctly marked as Optional in the schema (conditions in backend config)
- Files changed:
  - internal/generated/source_mongodb.go (updated descriptions for ssh_host, ssh_port, ssh_user, ssh_public_key)
- **Learnings for future iterations:**
  - MongoDB uses the same SSH conditional field pattern as other sources
  - SSH fields (host, port, user, public_key) are conditionally required when ssh.enabled=true
  - When fields are already Optional but missing condition documentation, only descriptions need updating
  - The schema schema attributes were already correct; this story focused on documentation clarity
---

## 2026-01-22 19:45 - US-009
- What was implemented:
  - Audited DynamoDB backend config at python-be-streamkap/app/sources/plugins/dynamodb/configuration.latest.json
  - Confirmed NO conditional fields exist in DynamoDB configuration (no `conditions` arrays on any fields)
  - Verified DynamoDB Terraform schema (internal/generated/source_dynamodb.go) is already correct
  - Cross-referenced with audit report (docs/audits/conditional-fields-audit.md) - DynamoDB not listed
  - Build verification passed
- Files changed:
  - None (no code changes needed - verification only)
- **Learnings for future iterations:**
  - Not all connectors have conditional fields - DynamoDB is a simpler configuration
  - DynamoDB doesn't have SSH tunneling or heartbeat/signal table configurations
  - Always check the audit report first to see if connector has known issues
  - Some stories may be verification-only when the connector doesn't have the issue being addressed
  - Simpler connectors (like DynamoDB) may have already-correct schemas
---

## 2026-01-22 20:30 - US-010
- What was implemented:
  - Read SQL Server backend config from python-be-streamkap/app/sources/plugins/sqlserveraws/configuration.latest.json
  - Identified 5 conditional fields:
    - heartbeat_data_collection_schema_or_database: conditionally required when heartbeat_enabled is true
    - ssh_host: conditionally required when ssh_enabled is true
    - ssh_port: conditionally required when ssh_enabled is true
    - ssh_user: conditionally required when ssh_enabled is true
    - ssh_public_key: conditionally required when ssh_enabled is true
  - All fields were already correctly marked as Optional in the Terraform schema
  - Updated descriptions for all 5 fields to document when they are conditionally required
- Files changed:
  - internal/generated/source_sqlserveraws.go (updated descriptions for conditional fields)
- **Learnings for future iterations:**
  - SQL Server follows the same SSH conditional field pattern as other sources (MongoDB, etc.)
  - SQL Server uses "streamkap" as default schema (same as other sources)
  - Schema is at internal/generated/source_sqlserveraws.go (connector code is "sqlserveraws")
  - The generated schema was already correct - only documentation/descriptions needed updating
---

## 2026-01-22 21:00 - US-011
- What was implemented:
  - Read Kafka Direct backend config from python-be-streamkap/app/sources/plugins/kafkadirect/configuration.latest.json
  - Identified 1 conditional field:
    - schemas_enable: conditionally required when format is "json" (condition: `format` EQ `json`)
  - The field was already correctly marked as Optional with Computed and a default value of false
  - Updated descriptions for schemas_enable to document the conditional requirement
- Files changed:
  - internal/generated/source_kafkadirect.go (updated description for schemas_enable field)
- **Learnings for future iterations:**
  - Kafka Direct is a simpler connector with fewer conditional fields
  - The schemas_enable field only applies when format="json" (makes sense - schemas are part of JSON format)
  - File is at internal/generated/source_kafkadirect.go (not in internal/resource/source/)
  - When a field is already Optional, only the description needs to be updated to document the condition
---

## 2026-01-22 21:45 - US-012
- What was implemented:
  - Read backend configs for AlloyDB, MariaDB, Supabase, PlanetScale from python-be-streamkap/app/sources/plugins/
  - AlloyDB (PostgreSQL-based):
    - signal_data_collection_schema_or_database: Changed from Required to Optional (conditionally required when snapshot_read_only="No")
    - heartbeat_data_collection_schema_or_database: Changed from Required to Optional (conditionally required when heartbeat_enabled=true AND snapshot_read_only="No")
  - Supabase (PostgreSQL-based):
    - Same changes as AlloyDB - identical conditional fields pattern
  - MariaDB:
    - heartbeat_data_collection_schema_or_database: Changed from Required to Optional (conditionally required when heartbeat_enabled=true AND snapshot_gtid="No")
    - signal_data_collection_schema_or_database was already Optional - no changes needed
  - PlanetScale (Vitess-based):
    - SSH fields (ssh_host, ssh_port, ssh_user, ssh_public_key) were already Optional - no changes needed
  - Updated schema_test.go to remove signal_data_collection and heartbeat_data_collection from PostgreSQL required attrs
  - Updated schema snapshots for backwards compatibility
- Files changed:
  - internal/generated/source_alloydb.go (signal_data_collection and heartbeat_data_collection to Optional)
  - internal/generated/source_supabase.go (signal_data_collection and heartbeat_data_collection to Optional)
  - internal/generated/source_mariadb.go (heartbeat_data_collection to Optional)
  - internal/provider/schema_test.go (updated PostgreSQL required attrs)
  - internal/provider/testdata/schemas/source_postgresql_v1.json (updated snapshot)
  - internal/provider/testdata/schemas/source_mysql_v1.json (updated snapshot)
  - internal/provider/testdata/schemas/source_sqlserver_v1.json (updated snapshot)
- **Learnings for future iterations:**
  - PostgreSQL-based sources (AlloyDB, Supabase) share similar conditional field patterns
  - MariaDB uses snapshot_gtid instead of snapshot_read_only for its condition
  - PlanetScale (Vitess) has simpler conditional fields - just SSH tunnel fields
  - When changing Required -> Optional for major sources, schema tests may need updates
  - Schema snapshots automatically update all sources, so check git diff to understand scope of changes
---

## 2026-01-22 22:30 - US-013
- What was implemented:
  - Read backend configs for Oracle, OracleAWS, DB2, DocumentDB from python-be-streamkap/app/sources/plugins/
  - Oracle:
    - heartbeat_data_collection_schema_or_database: Changed from Required to Optional (conditionally required when heartbeat_enabled=true)
    - SSH fields (ssh_host, ssh_port, ssh_user, ssh_public_key): Already Optional - updated descriptions to document condition
  - OracleAWS (Oracle RDS):
    - Same changes as Oracle - identical conditional fields pattern
  - DB2:
    - SSH fields only (ssh_host, ssh_port, ssh_user, ssh_public_key): Already Optional - updated descriptions to document condition
    - No heartbeat_data_collection field (heartbeat.interval.ms is static at 60000)
  - DocumentDB:
    - SSH fields only (ssh_host, ssh_port, ssh_user, ssh_public_key): Already Optional - updated descriptions to document condition
    - No heartbeat_data_collection field
- Files changed:
  - internal/generated/source_oracle.go (heartbeat_data_collection to Optional, SSH field descriptions updated)
  - internal/generated/source_oracleaws.go (heartbeat_data_collection to Optional, SSH field descriptions updated)
  - internal/generated/source_db2.go (SSH field descriptions updated)
  - internal/generated/source_documentdb.go (SSH field descriptions updated)
- **Learnings for future iterations:**
  - Oracle and OracleAWS share similar patterns to PostgreSQL for heartbeat_data_collection
  - DB2 and DocumentDB are simpler - only SSH conditional fields, no heartbeat table configuration
  - Oracle uses pluggable database (database_pdb_name) which DocumentDB doesn't have
  - All connectors follow same SSH tunnel conditional pattern: fields required when ssh_enabled=true
  - When checking backend config, some connectors have heartbeat as a static value vs user-configurable
---

## 2026-01-22 23:15 - US-014
- What was implemented:
  - Read backend configs for MongoDBHosted, Elasticsearch, Redis, Vitess, S3, Webhook from python-be-streamkap/app/sources/plugins/
  - Elasticsearch:
    - http_auth_user: Changed from Required to Optional (conditionally required when http_auth is "Basic")
    - http_auth_password: Changed from Required to Optional (conditionally required when http_auth is "Basic")
  - Redis:
    - redis_stream_name: Changed from Required to Optional (conditionally required when connector_class_type is "Stream")
    - topic: Changed from Required to Optional (conditionally required based on complex OR condition involving connector_class_type and topic_use_stream_name)
    - Updated descriptions for all Stream-specific and Keys-specific conditional fields
  - MongoDBHosted:
    - SSH fields (ssh_host, ssh_port, ssh_user, ssh_public_key): Already Optional - updated descriptions to document condition
  - Vitess:
    - SSH fields (ssh_host, ssh_port, ssh_user, ssh_public_key): Already Optional - updated descriptions to document condition
  - S3: No conditional fields found in backend config - no changes needed
  - Webhook: No conditional fields found in backend config - no changes needed
- Files changed:
  - internal/generated/source_elasticsearch.go (http_auth_user and http_auth_password to Optional, updated descriptions)
  - internal/generated/source_redis.go (redis_stream_name and topic to Optional, updated descriptions for conditional fields)
  - internal/generated/source_mongodbhosted.go (SSH field descriptions updated)
  - internal/generated/source_vitess.go (SSH field descriptions updated)
- **Learnings for future iterations:**
  - Redis has a complex conditional structure with Stream vs Keys connector types
  - Redis conditions use OR logic in some cases (e.g., topic field required when Keys OR when Stream with topic_use_stream_name=false)
  - Elasticsearch uses Basic authentication conditionally - fields required only when http_auth is "Basic"
  - Not all connectors have conditional fields - S3 and Webhook are simpler connectors
  - MongoDBHosted shares the same backend config as MongoDB but is in a separate plugin folder
  - Vitess follows the same SSH conditional pattern as other database connectors
---

## 2026-01-22 23:45 - US-015
- What was implemented:
  - Read Snowflake backend config from python-be-streamkap/app/destinations/plugins/snowflake/configuration.latest.json
  - Identified 9 fields with conditions arrays:
    - snowflake_private_key_passphrase: conditionally required when snowflake_private_key_passphrase_secured is true
    - hard_delete: conditionally required when ingestion_mode is 'upsert'
    - schema_evolution: conditionally required when ingestion_mode is 'upsert'
    - use_hybrid_tables: conditionally required when ingestion_mode is 'upsert'
    - apply_dynamic_table_script: conditionally required when ingestion_mode is 'append'
    - create_sql_execute: conditionally required when ingestion_mode is 'append' AND apply_dynamic_table_script is true
    - sql_table_name: conditionally required when ingestion_mode is 'append' AND apply_dynamic_table_script is true
    - create_sql_data: conditionally required when ingestion_mode is 'append' AND apply_dynamic_table_script is true
    - auto_qa_dedupe_table_mapping: conditionally required when ingestion_mode is 'append' AND apply_dynamic_table_script is true
  - All fields were already correctly marked as Optional in the Terraform schema
  - Updated descriptions for all 9 fields to document when they are conditionally required
- Files changed:
  - internal/generated/destination_snowflake.go (updated descriptions for conditional fields)
- **Learnings for future iterations:**
  - Destination connectors follow a different conditional pattern than sources
  - Snowflake has two main ingestion modes: 'upsert' and 'append', with different features available for each
  - Dynamic table features (create_sql_execute, sql_table_name, create_sql_data, auto_qa_dedupe_table_mapping) require BOTH ingestion_mode='append' AND apply_dynamic_table_script=true
  - The passphrase field is conditionally required based on a boolean toggle field (passphrase_secured)
  - The generated schema file is at internal/generated/destination_snowflake.go (not internal/resource/destination/)
---
