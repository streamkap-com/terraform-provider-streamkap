---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "streamkap_source_dynamodb Resource - terraform-provider-streamkap"
subcategory: ""
description: |-
  Manages a DynamoDB source connector.
  This resource creates and manages a DynamoDB source for Streamkap data pipelines.
  Documentation https://docs.streamkap.com/streamkap-provider-for-terraform
---

# streamkap_source_dynamodb (Resource)

Manages a **DynamoDB source connector**.

This resource creates and manages a DynamoDB source for Streamkap data pipelines.

[Documentation](https://docs.streamkap.com/streamkap-provider-for-terraform)



<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `aws_access_key_id` (String, Sensitive) AWS Access Key ID

**Security:** This value is marked sensitive and will not appear in CLI output or logs.
- `aws_region` (String) AWS Region
- `aws_secret_key` (String, Sensitive) AWS Secret Key

**Security:** This value is marked sensitive and will not appear in CLI output or logs.
- `name` (String) Name of the source
- `s3_export_bucket_name` (String) used for backfill (snapshot)
- `table_include_list` (String) Source tables to sync.

### Optional

- `array_encoding_json` (Boolean) Force nested lists as JSON string Defaults to `true`.
- `batch_size` (Number)
- `dynamodb_service_endpoint` (String) Dynamodb Service Endpoint (optional)
- `full_export_expiration_time_ms` (Number) Full Export Expiration Time (ms) Defaults to `0`.
- `incremental_snapshot_chunk_size` (Number) Incremental snapshot chunk size Defaults to `0`.
- `incremental_snapshot_max_threads` (Number) Incremental snapshot max threads Defaults to `0`.
- `poll_timeout_ms` (Number) Poll Timeout (ms) Defaults to `0`.
- `signal_kafka_poll_timeout_ms` (Number) Signal Kafka Poll Timeout (ms) Defaults to `0`.
- `snapshot_parallel_time_offset` (Number) If > 0, snapshot will run in parallel with streaming and snapshot records _streamkap_ts_ms will be set back in time by this amount to prioritize CDC events downstream Defaults to `0`.
- `struct_encoding_json` (Boolean) Force nested maps as JSON string Defaults to `true`.
- `tasks_max` (Number) The maximum number of active tasks Defaults to `10`.
- `timeouts` (Block, Optional) (see [below for nested schema](#nestedblock--timeouts))

### Read-Only

- `connector` (String) Connector type
- `id` (String) Unique identifier for the source

<a id="nestedblock--timeouts"></a>
### Nested Schema for `timeouts`

Optional:

- `create` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
- `delete` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
- `update` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).

## Import

Import is supported using the following syntax:

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
# Source DynamoDB can be imported by specifying the identifier.
terraform import streamkap_source_dynamodb.example-source-dynamodb 00000000000000000000000000
```
