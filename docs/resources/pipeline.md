---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "streamkap_pipeline Resource - terraform-provider-streamkap"
subcategory: ""
description: |-
  Pipeline resource
---

# streamkap_pipeline (Resource)

Pipeline resource

## Example Usage

```terraform
terraform {
  required_providers {
    streamkap = {
      source  = "streamkap-com/streamkap"
      version = ">= 2.0.0"
    }
  }
  required_version = ">= 1.0.0"
}

provider "streamkap" {}

data "streamkap_tag" "development-tag" {
  id = "670e5ca40afe1d3983ce0c22" # Development tag
}

data "streamkap_tag" "production-tag" {
  id = "670e5bab0d119c0d1f8cda9d" # Production tag
}

variable "source_postgresql_hostname" {
  type        = string
  description = "The hostname of the PostgreSQL database"
}

variable "source_postgresql_password" {
  type        = string
  sensitive   = true
  description = "The password of the PostgreSQL database"
}

resource "streamkap_source_postgresql" "example-source-postgresql" {
  name                                      = "example-source-postgresql"
  database_hostname                         = var.source_postgresql_hostname
  database_port                             = 5432
  database_user                             = "postgresql"
  database_password                         = var.source_postgresql_password
  database_dbname                           = "postgres"
  database_sslmode                          = "require"
  schema_include_list                       = "public"
  table_include_list                        = "public.users,public.itst_scen20240528100603,public.itst_scen20240528103635,public.itst_scen20240530141046"
  signal_data_collection_schema_or_database = "streamkap"
  heartbeat_enabled                         = false
  include_source_db_name_in_table_name      = false
  slot_name                                 = "terraform_pgoutput_slot"
  publication_name                          = "terraform_pub"
  binary_handling_mode                      = "bytes"
  ssh_enabled                               = false
}

variable "destination_snowflake_url_name" {
  type        = string
  description = "The URL name of the Snowflake database"
}

variable "destination_snowflake_private_key" {
  type        = string
  sensitive   = true
  description = "The private key of the Snowflake database"
}

variable "destination_snowflake_key_passphrase" {
  type        = string
  sensitive   = true
  description = "The passphrase of the private key of the Snowflake database"
}

resource "streamkap_destination_snowflake" "example-destination-snowflake" {
  name                             = "example-destination-snowflake"
  snowflake_url_name               = var.destination_snowflake_url_name
  snowflake_user_name              = "STREAMKAP_USER_JUNIT"
  snowflake_private_key            = var.destination_snowflake_private_key
  snowflake_private_key_passphrase = var.destination_snowflake_key_passphrase
  sfwarehouse                      = "STREAMKAP_WH"
  snowflake_database_name          = "JUNIT"
  snowflake_schema_name            = "JUNIT"
  snowflake_role_name              = "STREAMKAP_ROLE_JUNIT"
  ingestion_mode                   = "upsert"
  hard_delete                      = true
  use_hybrid_tables                = false
  apply_dynamic_table_script       = false
  dynamic_table_target_lag         = 60
  cleanup_task_schedule            = 120
}

data "streamkap_transform" "example-transform" {
  id = "63975020676fa8f369d55001"
}

data "streamkap_transform" "another-example-transform" {
  id = "63975020676fa8f369d55005"
}

resource "streamkap_pipeline" "example-pipeline" {
  name                = "example-pipeline"
  snapshot_new_tables = true
  source = {
    id        = streamkap_source_postgresql.example-source-postgresql.id
    name      = streamkap_source_postgresql.example-source-postgresql.name
    connector = streamkap_source_postgresql.example-source-postgresql.connector
    topics = [
      "public.itst_scen20240530141046",
      "public.itst_scen20240528100603",
      "public.itst_scen20240528103635",
      "public.users",
    ]
  }
  destination = {
    id        = streamkap_destination_snowflake.example-destination-snowflake.id
    name      = streamkap_destination_snowflake.example-destination-snowflake.name
    connector = streamkap_destination_snowflake.example-destination-snowflake.connector
  }
  transforms = [
    {
      id = data.streamkap_transform.example-transform.id
      topics = [
        "public.itst_scen20240530123456",
        "random_topic",
      ]
    },
    {
      id = data.streamkap_transform.another-example-transform.id
      topics = [
        "public.itst_scen20240530654321",
        "public.itst_scen20240528121212",
      ]
    }
  ]
  tags = [
    data.streamkap_tag.development-tag.id,
  ]
}

output "example-pipeline" {
  value = streamkap_pipeline.example-pipeline.id
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `destination` (Object) Pipeline destination (see [below for nested schema](#nestedatt--destination))
- `name` (String) Pipeline name
- `source` (Object) Pipeline source (see [below for nested schema](#nestedatt--source))

### Optional

- `snapshot_new_tables` (Boolean) Whether to snapshot new tables (topics) or not
- `tags` (Set of String) List of tag IDs for the pipeline. Default is `["670e5ca40afe1d3983ce0c22"]`, which is Streamkap system `Development` tag.
- `transforms` (Attributes List) Pipeline transforms (see [below for nested schema](#nestedatt--transforms))

### Read-Only

- `id` (String) Pipeline identifier

<a id="nestedatt--destination"></a>
### Nested Schema for `destination`

Required:

- `connector` (String)
- `id` (String)
- `name` (String)


<a id="nestedatt--source"></a>
### Nested Schema for `source`

Required:

- `connector` (String)
- `id` (String)
- `name` (String)
- `topics` (Set of String)


<a id="nestedatt--transforms"></a>
### Nested Schema for `transforms`

Required:

- `id` (String) Transform identifier
- `topics` (Set of String) List of transform topics' names

## Import

Import is supported using the following syntax:

```shell
# Destination Snowflake can be imported by specifying the identifier.
terraform import streamkap_pipeline.example-pipeline 665e894ebb3753f38d983cee
```
