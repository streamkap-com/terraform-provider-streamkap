---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "streamkap_destination_snowflake Resource - terraform-provider-streamkap"
subcategory: ""
description: |-
  Destination Snowflake resource
---

# streamkap_destination_snowflake (Resource)

Destination Snowflake resource

## Example Usage

```terraform
terraform {
  required_providers {
    streamkap = {
      source  = "streamkap-com/streamkap"
      version = ">= 2.0.0"
    }
  }
  required_version = ">= 1.0.0"
}

provider "streamkap" {}

variable "destination_snowflake_url_name" {
  type        = string
  description = "The URL name of the Snowflake database"
}
variable "destination_snowflake_private_key" {
  type        = string
  sensitive   = true
  description = "The private key of the Snowflake database"
}
variable "destination_snowflake_key_passphrase" {
  type        = string
  sensitive   = true
  description = "The passphrase of the private key of the Snowflake database"
}
resource "streamkap_destination_snowflake" "example-destination-snowflake" {
  name                             = "example-destination-snowflake"
  snowflake_url_name               = var.destination_snowflake_url_name
  snowflake_user_name              = "STREAMKAP_USER_JUNIT"
  snowflake_private_key            = var.destination_snowflake_private_key
  snowflake_private_key_passphrase = var.destination_snowflake_key_passphrase
  sfwarehouse                      = "STREAMKAP_WH"
  snowflake_database_name          = "JUNIT"
  snowflake_schema_name            = "JUNIT"
  snowflake_role_name              = "STREAMKAP_ROLE_JUNIT"
  ingestion_mode                   = "upsert"
  hard_delete                      = true
  use_hybrid_tables                = false
  apply_dynamic_table_script       = false
  dynamic_table_target_lag         = 60
  cleanup_task_schedule            = 120
}

output "example-destination-snowflake" {
  value = streamkap_destination_snowflake.example-destination-snowflake.id
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `name` (String) Destination name
- `snowflake_database_name` (String) The name of the database that contains the table to insert rows into.
- `snowflake_private_key` (String, Sensitive) The private key to authenticate the user. Include only the key, not the header or footer. If the key is split across multiple lines, remove the line breaks.
- `snowflake_schema_name` (String) The name of the schema that contains the table to insert rows into.
- `snowflake_url_name` (String) The URL for accessing your Snowflake account. This URL must include your account identifier. Note that the protocol (https://) and port number are optional.
- `snowflake_user_name` (String) User login name for the Snowflake account.

### Optional

- `apply_dynamic_table_script` (Boolean) Specifies whether the connector should create Dyanmic Tables & Cleanup Task (applies to `append` mode only)
- `cleanup_task_schedule` (Number) Schedule for cleanup task in minutes (applies to `append` mode only)
- `create_sql_data` (String) Custom SQL mustache template input JSON data. Use TABLE_DATA dictionary to set table specific data.
- `create_sql_execute` (String) Custom SQL mustache template to be run the first time a record is streamed for each table.
- `dynamic_table_target_lag` (Number) Target lag for dynamic tables in minutes (applies to `append` mode only)
- `hard_delete` (Boolean) Specifies whether the connector processes DELETE or tombstone events and removes the corresponding row from the database (applies to `upsert` only)
- `ingestion_mode` (String) `upsert` or `append` modes are available
- `schema_evolution` (String) Controls how schema evolution is handled by the sink connector. For pipelines with pre-created destination tables, set to `none`
- `sfwarehouse` (String) The name of the Snowflake warehouse.
- `snowflake_private_key_passphrase` (String, Sensitive) If the value is not empty, this phrase is used to try to decrypt the private key.
- `snowflake_role_name` (String) The name of an existing role with necessary privileges (for Streamkap) assigned to the Username.
- `sql_table_name` (String) Dynamic Table Name mustache template. Can be used as `{{dynamicTableName}}` in dynamic table creation SQL. It can use input JSON data for more complex mappings and logic.
- `use_hybrid_tables` (Boolean) Specifies whether the connector should create Hybrid Tables (applies to `upsert` only)

### Read-Only

- `connector` (String)
- `id` (String) Destination Snowflake identifier

## Import

Import is supported using the following syntax:

```shell
# Destination Snowflake can be imported by specifying the identifier.
terraform import streamkap_destination_snowflake.example-destination-snowflake 665e894ebb3753f38d983cee
```
