---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "streamkap_source_sqlserver Resource - terraform-provider-streamkap"
subcategory: ""
description: |-
  Manages a SQL Server source connector.
  This resource creates and manages a SQL Server source for Streamkap data pipelines.
  Documentation https://docs.streamkap.com/streamkap-provider-for-terraform
---

# streamkap_source_sqlserver (Resource)

Manages a **SQL Server source connector**.

This resource creates and manages a SQL Server source for Streamkap data pipelines.

[Documentation](https://docs.streamkap.com/streamkap-provider-for-terraform)



<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `database_hostname` (String) The Endpoint of the SQL Server database server. For example, sqlserverdb.abcdefgh.us-west-2.rds.amazonaws.com
- `database_names` (String) Database to stream from.
- `database_password` (String, Sensitive) Password to access the database

**Security:** This value is marked sensitive and will not appear in CLI output or logs.
- `database_user` (String) Username to access the database
- `name` (String) Name of the source
- `schema_include_list` (String) Schemas to include.
- `table_include_list` (String) Source tables to sync.

### Optional

- `binary_handling_mode` (String) Specifies how the data for binary columns e.g. blob, binary, varbinary should be represented. This setting depends on what the destination is. See the documentation for more details. Defaults to `bytes`. Valid values: `bytes`, `base64`, `base64-url-safe`, `hex`.
- `column_exclude_list` (String) An optional, comma-separated list of regular expressions that match the fully-qualified names of columns that should be excluded from change event record values. Fully-qualified names for columns are of the form schemaName.tableName.columnName.
- `database_encrypt` (String) Use TLS encryption with the SQL Server? Defaults to `true`. Valid values: `true`, `false`.
- `database_port` (Number) SQL Server Port. For example, 1433 Defaults to `1433`.
- `heartbeat_data_collection_schema_or_database` (String) Streamkap will use a table in this schema to simulate activity from the source database to keep the database transaction log 'alive'.

**Conditionally Required:** This field is required when `heartbeat_enabled` is `true`. Defaults to `streamkap`.
- `heartbeat_enabled` (Boolean) Heartbeats are used to monitor whether the connector is still receiving change events from the database, especially when there is low and intermittent traffic. Defaults to `true`.
- `schema_history_internal_store_only_captured_databases_ddl` (Boolean) Specifies whether the connector records schema structures from all logical databases in the database instance or only captured databases. Enabling this when you have many databases in your instance can improve performance and avoid timeouts. Defaults to `false`.
- `schema_history_internal_store_only_captured_tables_ddl` (Boolean) Specifies whether the connector records schema structures from all logical tables in the captured schemas or databases, or only captured tables. Enabling this when you have many tables can improve performance and avoid timeouts. Defaults to `false`.
- `signal_data_collection_schema_or_database` (String) Streamkap will use a table in this schema to monitor incremental snapshotting. Follow the instructions in the documentation for creating this table and specify which schema to use here. Defaults to `streamkap`.
- `snapshot_custom_table_config` (Attributes Map) Explicitly set nb of parallel chunks for tables. Format: {"db.Some_Tbl": {"chunks": 5}}. This allows manual settings for parallelization when stats are outdated and estimated table size cannot be computed reliably (see [below for nested schema](#nestedatt--snapshot_custom_table_config))
- `ssh_enabled` (Boolean) Streamkap will connect to SSH server in your network which has access to your database. This is necessary if Streamkap cannot connect directly to your database. Defaults to `false`.
- `ssh_host` (String) Hostname of your SSH server.

**Conditionally Required:** This field is required when `ssh_enabled` is `true`.
- `ssh_port` (Number) Port of your SSH server.

**Conditionally Required:** This field is required when `ssh_enabled` is `true`. Defaults to `22`.
- `ssh_public_key` (String) Public key to add to SSH server.

**Conditionally Required:** This field is required when `ssh_enabled` is `true`. Defaults to `<SSH.PUBLIC.KEY>`.
- `ssh_user` (String) User that allows Streamkap to connect to SSH server.

**Conditionally Required:** This field is required when `ssh_enabled` is `true`. Defaults to `streamkap`.
- `streamkap_snapshot_large_table_threshold` (Number) The threshold in MB for a Large Table to require multiple chunks to be read in parallel. Defaults to `20000`.
- `streamkap_snapshot_parallelism` (Number) How many parallel chunk requests to send to the source DB. Defaults to `1`.
- `timeouts` (Block, Optional) (see [below for nested schema](#nestedblock--timeouts))
- `transforms_insert_static_key1_static_field` (String) The name of the static field to be added to the message key.
- `transforms_insert_static_key1_static_value` (String) The value of the static field to be added to the message key.
- `transforms_insert_static_value1_static_field` (String) The name of the static field to be added to the message value.
- `transforms_insert_static_value1_static_value` (String) The value of the static field to be added to the message value.

### Read-Only

- `connector` (String) Connector type
- `id` (String) Unique identifier for the source

<a id="nestedatt--snapshot_custom_table_config"></a>
### Nested Schema for `snapshot_custom_table_config`

Required:

- `chunks` (Number)


<a id="nestedblock--timeouts"></a>
### Nested Schema for `timeouts`

Optional:

- `create` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
- `delete` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
- `update` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).

## Import

Import is supported using the following syntax:

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
# Source SQL Server can be imported by specifying the identifier.
terraform import streamkap_source_sqlserver.example-source-sqlserver 686dfd294321ea8a67d6d190
```
